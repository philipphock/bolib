{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([0.1857, 0.4319], dtype=torch.float64),\n",
       "  tensor([0.3862], dtype=torch.float64)),\n",
       " (tensor([0.0928, 0.0522], dtype=torch.float64),\n",
       "  tensor([0.3950], dtype=torch.float64)),\n",
       " (tensor([0.2200, 0.4238], dtype=torch.float64),\n",
       "  tensor([0.3438], dtype=torch.float64)),\n",
       " (tensor([0.4286, 0.9041], dtype=torch.float64),\n",
       "  tensor([0.7927], dtype=torch.float64)),\n",
       " (tensor([0.7218, 0.0085], dtype=torch.float64),\n",
       "  tensor([0.5733], dtype=torch.float64)),\n",
       " (tensor([0.5329, 0.5311], dtype=torch.float64),\n",
       "  tensor([0.5240], dtype=torch.float64)),\n",
       " (tensor([0.6375, 0.5750], dtype=torch.float64),\n",
       "  tensor([0.6725], dtype=torch.float64)),\n",
       " (tensor([0.1635, 0.2229], dtype=torch.float64),\n",
       "  tensor([0.1994], dtype=torch.float64)),\n",
       " (tensor([0.0247, 0.6596], dtype=torch.float64),\n",
       "  tensor([0.7749], dtype=torch.float64)),\n",
       " (tensor([0.0554, 0.0596], dtype=torch.float64),\n",
       "  tensor([0.4250], dtype=torch.float64)),\n",
       " (tensor([0.3629, 0.5407], dtype=torch.float64),\n",
       "  tensor([0.3637], dtype=torch.float64)),\n",
       " (tensor([0.6870, 0.8449], dtype=torch.float64),\n",
       "  tensor([0.9919], dtype=torch.float64)),\n",
       " (tensor([0.6555, 0.5490], dtype=torch.float64),\n",
       "  tensor([0.6645], dtype=torch.float64)),\n",
       " (tensor([0.8912, 0.6264], dtype=torch.float64),\n",
       "  tensor([0.9775], dtype=torch.float64)),\n",
       " (tensor([0.0882, 0.0789], dtype=torch.float64),\n",
       "  tensor([0.3729], dtype=torch.float64)),\n",
       " (tensor([0.9021, 0.8280], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.9220, 0.4395], dtype=torch.float64),\n",
       "  tensor([0.8216], dtype=torch.float64)),\n",
       " (tensor([0.4244, 0.5438], dtype=torch.float64),\n",
       "  tensor([0.4282], dtype=torch.float64)),\n",
       " (tensor([0.5425, 0.0942], dtype=torch.float64),\n",
       "  tensor([0.3082], dtype=torch.float64)),\n",
       " (tensor([0.9549, 0.2258], dtype=torch.float64),\n",
       "  tensor([0.6407], dtype=torch.float64)),\n",
       " (tensor([0.8398, 0.9456], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.6213, 0.9428], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.8797, 0.9511], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.2833, 0.7438], dtype=torch.float64),\n",
       "  tensor([0.6005], dtype=torch.float64)),\n",
       " (tensor([0.4420, 0.0089], dtype=torch.float64),\n",
       "  tensor([0.2930], dtype=torch.float64)),\n",
       " (tensor([0.1354, 0.8183], dtype=torch.float64),\n",
       "  tensor([0.8229], dtype=torch.float64)),\n",
       " (tensor([0.2645, 0.9668], dtype=torch.float64),\n",
       "  tensor([0.8424], dtype=torch.float64)),\n",
       " (tensor([0.7910, 0.9740], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.0136, 0.1314], dtype=torch.float64),\n",
       "  tensor([0.3951], dtype=torch.float64)),\n",
       " (tensor([0.6436, 0.6008], dtype=torch.float64),\n",
       "  tensor([0.7044], dtype=torch.float64)),\n",
       " (tensor([0.8885, 0.4792], dtype=torch.float64),\n",
       "  tensor([0.8276], dtype=torch.float64)),\n",
       " (tensor([0.3895, 0.7029], dtype=torch.float64),\n",
       "  tensor([0.5524], dtype=torch.float64)),\n",
       " (tensor([0.6758, 0.5372], dtype=torch.float64),\n",
       "  tensor([0.6731], dtype=torch.float64)),\n",
       " (tensor([0.5347, 0.3523], dtype=torch.float64),\n",
       "  tensor([0.3470], dtype=torch.float64)),\n",
       " (tensor([0.1603, 0.2976], dtype=torch.float64),\n",
       "  tensor([0.2773], dtype=torch.float64)),\n",
       " (tensor([0.5558, 0.6037], dtype=torch.float64),\n",
       "  tensor([0.6196], dtype=torch.float64)),\n",
       " (tensor([0.4845, 0.5399], dtype=torch.float64),\n",
       "  tensor([0.4844], dtype=torch.float64)),\n",
       " (tensor([0.9539, 0.8271], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.1669, 0.3210], dtype=torch.float64),\n",
       "  tensor([0.2941], dtype=torch.float64)),\n",
       " (tensor([0.4080, 0.5756], dtype=torch.float64),\n",
       "  tensor([0.4435], dtype=torch.float64)),\n",
       " (tensor([0.0743, 0.6656], dtype=torch.float64),\n",
       "  tensor([0.7313], dtype=torch.float64)),\n",
       " (tensor([0.4855, 0.6800], dtype=torch.float64),\n",
       "  tensor([0.6255], dtype=torch.float64)),\n",
       " (tensor([0.2415, 0.2955], dtype=torch.float64),\n",
       "  tensor([0.1940], dtype=torch.float64)),\n",
       " (tensor([0.1673, 0.5038], dtype=torch.float64),\n",
       "  tensor([0.4764], dtype=torch.float64)),\n",
       " (tensor([0.6720, 0.7448], dtype=torch.float64),\n",
       "  tensor([0.8769], dtype=torch.float64)),\n",
       " (tensor([0.8250, 0.6190], dtype=torch.float64),\n",
       "  tensor([0.9039], dtype=torch.float64)),\n",
       " (tensor([0.5361, 0.1631], dtype=torch.float64),\n",
       "  tensor([0.2331], dtype=torch.float64)),\n",
       " (tensor([0.7346, 0.0565], dtype=torch.float64),\n",
       "  tensor([0.5381], dtype=torch.float64)),\n",
       " (tensor([0.9404, 0.1900], dtype=torch.float64),\n",
       "  tensor([0.6104], dtype=torch.float64)),\n",
       " (tensor([0.9235, 0.0736], dtype=torch.float64),\n",
       "  tensor([0.7098], dtype=torch.float64)),\n",
       " (tensor([0.0524, 0.0284], dtype=torch.float64),\n",
       "  tensor([0.4593], dtype=torch.float64)),\n",
       " (tensor([0.9232, 0.7298], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.1214, 0.8086], dtype=torch.float64),\n",
       "  tensor([0.8272], dtype=torch.float64)),\n",
       " (tensor([0.5691, 0.2705], dtype=torch.float64),\n",
       "  tensor([0.2995], dtype=torch.float64)),\n",
       " (tensor([0.7774, 0.6642], dtype=torch.float64),\n",
       "  tensor([0.9016], dtype=torch.float64)),\n",
       " (tensor([0.6256, 0.7997], dtype=torch.float64),\n",
       "  tensor([0.8853], dtype=torch.float64)),\n",
       " (tensor([0.6327, 0.5423], dtype=torch.float64),\n",
       "  tensor([0.6350], dtype=torch.float64)),\n",
       " (tensor([0.1550, 0.8860], dtype=torch.float64),\n",
       "  tensor([0.8710], dtype=torch.float64)),\n",
       " (tensor([0.2014, 0.2132], dtype=torch.float64),\n",
       "  tensor([0.1518], dtype=torch.float64)),\n",
       " (tensor([0.8323, 0.3887], dtype=torch.float64),\n",
       "  tensor([0.6810], dtype=torch.float64)),\n",
       " (tensor([0.8859, 0.6442], dtype=torch.float64),\n",
       "  tensor([0.9901], dtype=torch.float64)),\n",
       " (tensor([0.1907, 0.6752], dtype=torch.float64),\n",
       "  tensor([0.6246], dtype=torch.float64)),\n",
       " (tensor([0.9926, 0.0640], dtype=torch.float64),\n",
       "  tensor([0.7886], dtype=torch.float64)),\n",
       " (tensor([0.5658, 0.9529], dtype=torch.float64),\n",
       "  tensor([0.9787], dtype=torch.float64)),\n",
       " (tensor([0.2461, 0.7850], dtype=torch.float64),\n",
       "  tensor([0.6789], dtype=torch.float64)),\n",
       " (tensor([0.5096, 0.0049], dtype=torch.float64),\n",
       "  tensor([0.3647], dtype=torch.float64)),\n",
       " (tensor([0.4734, 0.2719], dtype=torch.float64),\n",
       "  tensor([0.2053], dtype=torch.float64)),\n",
       " (tensor([0.8331, 0.2143], dtype=torch.float64),\n",
       "  tensor([0.5074], dtype=torch.float64)),\n",
       " (tensor([0.8906, 0.1959], dtype=torch.float64),\n",
       "  tensor([0.5547], dtype=torch.float64)),\n",
       " (tensor([0.4092, 0.4418], dtype=torch.float64),\n",
       "  tensor([0.3110], dtype=torch.float64)),\n",
       " (tensor([0.1953, 0.2937], dtype=torch.float64),\n",
       "  tensor([0.2384], dtype=torch.float64)),\n",
       " (tensor([0.5590, 0.1923], dtype=torch.float64),\n",
       "  tensor([0.2266], dtype=torch.float64)),\n",
       " (tensor([0.4839, 0.9220], dtype=torch.float64),\n",
       "  tensor([0.8659], dtype=torch.float64)),\n",
       " (tensor([0.8395, 0.2809], dtype=torch.float64),\n",
       "  tensor([0.5804], dtype=torch.float64)),\n",
       " (tensor([0.0311, 0.7764], dtype=torch.float64),\n",
       "  tensor([0.8853], dtype=torch.float64)),\n",
       " (tensor([0.8088, 0.3793], dtype=torch.float64),\n",
       "  tensor([0.6480], dtype=torch.float64)),\n",
       " (tensor([0.5219, 0.1905], dtype=torch.float64),\n",
       "  tensor([0.1914], dtype=torch.float64)),\n",
       " (tensor([0.1125, 0.5321], dtype=torch.float64),\n",
       "  tensor([0.5596], dtype=torch.float64)),\n",
       " (tensor([0.6323, 0.4930], dtype=torch.float64),\n",
       "  tensor([0.5853], dtype=torch.float64)),\n",
       " (tensor([0.7404, 0.1738], dtype=torch.float64),\n",
       "  tensor([0.4266], dtype=torch.float64)),\n",
       " (tensor([0.0788, 0.1349], dtype=torch.float64),\n",
       "  tensor([0.3263], dtype=torch.float64)),\n",
       " (tensor([0.4927, 0.7468], dtype=torch.float64),\n",
       "  tensor([0.6995], dtype=torch.float64)),\n",
       " (tensor([0.2852, 0.5075], dtype=torch.float64),\n",
       "  tensor([0.3623], dtype=torch.float64)),\n",
       " (tensor([0.0927, 0.4121], dtype=torch.float64),\n",
       "  tensor([0.4594], dtype=torch.float64)),\n",
       " (tensor([0.2043, 0.2872], dtype=torch.float64),\n",
       "  tensor([0.2229], dtype=torch.float64)),\n",
       " (tensor([0.9519, 0.3933], dtype=torch.float64),\n",
       "  tensor([0.8053], dtype=torch.float64)),\n",
       " (tensor([0.7940, 0.7828], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.1760, 0.6651], dtype=torch.float64),\n",
       "  tensor([0.6291], dtype=torch.float64)),\n",
       " (tensor([0.7847, 0.7104], dtype=torch.float64),\n",
       "  tensor([0.9552], dtype=torch.float64)),\n",
       " (tensor([0.7568, 0.9353], dtype=torch.float64),\n",
       "  tensor([1.], dtype=torch.float64)),\n",
       " (tensor([0.5132, 0.8673], dtype=torch.float64),\n",
       "  tensor([0.8405], dtype=torch.float64)),\n",
       " (tensor([0.5599, 0.4056], dtype=torch.float64),\n",
       "  tensor([0.4255], dtype=torch.float64)),\n",
       " (tensor([0.5231, 0.4026], dtype=torch.float64),\n",
       "  tensor([0.3857], dtype=torch.float64)),\n",
       " (tensor([0.4543, 0.5433], dtype=torch.float64),\n",
       "  tensor([0.4577], dtype=torch.float64)),\n",
       " (tensor([0.3964, 0.4460], dtype=torch.float64),\n",
       "  tensor([0.3024], dtype=torch.float64)),\n",
       " (tensor([0.4609, 0.8738], dtype=torch.float64),\n",
       "  tensor([0.7947], dtype=torch.float64)),\n",
       " (tensor([0.5711, 0.5883], dtype=torch.float64),\n",
       "  tensor([0.6194], dtype=torch.float64)),\n",
       " (tensor([0.4412, 0.4348], dtype=torch.float64),\n",
       "  tensor([0.3360], dtype=torch.float64)),\n",
       " (tensor([0.7405, 0.6922], dtype=torch.float64),\n",
       "  tensor([0.8927], dtype=torch.float64)),\n",
       " (tensor([0.7262, 0.1879], dtype=torch.float64),\n",
       "  tensor([0.3983], dtype=torch.float64))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCHSIZE = 100\n",
    "TARGET = [0.34, 0.2]\n",
    "\n",
    "\n",
    "#r = torch.tensor([[random.uniform(0, 1), random.uniform(0, 1)]], dtype=torch.double)  \n",
    "def dif(tensor, target):\n",
    "  target = torch.tensor([target], dtype=torch.double)\n",
    "  r = target - tensor \n",
    "  r = torch.abs(r)\n",
    "  r = torch.sum(r)\n",
    "  r = torch.clamp(r,0,1)\n",
    "  return torch.tensor([[r]], dtype=torch.double)\n",
    "  \n",
    "\n",
    "\n",
    "def getSample():\n",
    "  return torch.tensor([[random.uniform(0, 1), random.uniform(0, 1)]], dtype=torch.double)  \n",
    "\n",
    "X = torch.tensor([], dtype=torch.double)\n",
    "Y = torch.tensor([], dtype=torch.double)\n",
    "\n",
    "for i in range(BATCHSIZE):\n",
    "  s = getSample()\n",
    "  X = torch.cat((X, s), dim=0)\n",
    "\n",
    "for i in X:\n",
    "  s = dif(i, TARGET)\n",
    "  Y = torch.cat((Y, s), dim=0)\n",
    "  \n",
    "\n",
    "\n",
    "list(zip(X, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.9986]])\n"
     ]
    }
   ],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "\n",
    "# thus, we rate the variables accordingly: A value closer to 0.34, 0.2 is rated with a lower number\n",
    "\n",
    "\n",
    "train_Y = standardize(Y)\n",
    "\n",
    "\n",
    "gp = SingleTaskGP(X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "\n",
    "UCB = UpperConfidenceBound(gp, beta=0.1)\n",
    "\n",
    "\n",
    "bounds = torch.stack([torch.zeros(2), torch.ones(2)])\n",
    "candidate, acq_value = optimize_acqf(\n",
    "    UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    ")\n",
    "\n",
    "print(candidate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qehvi(model, train_obj, sampler):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    # partition non-dominated space into disjoint rectangles\n",
    "    partitioning = NondominatedPartitioning(ref_point=ref_point, Y=train_obj)\n",
    "    acq_func = qExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=ref_point.tolist(),  # use known reference point\n",
    "        partitioning=partitioning,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=problem_bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200, \"nonnegative\": True},\n",
    "        sequential=True,\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x =  unnormalize(candidates.detach(), bounds=problem_bounds)\n",
    "    return new_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
